{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img\n",
    "src=\"https://www.imt-atlantique.fr/sites/default/files/Images/Ecole/charte-graphique/IMT_Atlantique_logo_RVB_Baseline_400x272.jpg\"\n",
    "WIDTH=200 HEIGHT=200>\n",
    "\n",
    "<CENTER>\n",
    "</br>\n",
    "<p><font size=\"5\"> TAF MCE - 2019</span></p>\n",
    "<p><font size=\"4\">  UE Numerical Methods </font></p>\n",
    "<p></p>\n",
    "<p><font size=\"5\">  Notebook 02: Julia lab - unconstrained optimization </font></p>\n",
    "</p></br>\n",
    "</p>\n",
    "</CENTER>\n",
    "\n",
    "----------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lab, we want first to test the benefit of backtracking against constant stepsize for gradient or newton algorithms. Then, we will consider the behavior of conjugate-gradient and Polack-Ribière technique that work without knowledge of the Hessian matrix of the function to be optimized.\n",
    "\n",
    "## <span style=\"color:#00B8DE\"> I - Function plot </span>\n",
    "\n",
    "**1)** Let us consider the function $f(x,y)=[(x-2)\\sin(y-1)]^2+x^2+y^2$. \n",
    "Visualize this function on the square with vertices $(\\pm 3,\\pm 3)$.\n",
    "\n",
    "## <span style=\"color:#00B8DE\"> II - Backtracking </span>\n",
    "\n",
    "**2)** Testing the benefit of backtracking. Calculate gradient of this function and implement gradient algorithm\n",
    "for constant stepsize equal to .1 and then .01 and using backtracking. Compare the numbers of iterations necessary for convergence with initialization at point $(−4, -2)$ and residual error for the distance to the optimum smaller than $10^{−3}$.\n",
    "\n",
    "## <span style=\"color:#00B8DE\"> III - Gradient and Newton </span>\n",
    "**3)** Implement Newton algorithm with backtracking to minimize $f(x,y)$ and compare results to gradient algorithm with backtracking.\n",
    "\n",
    "## <span style=\"color:#00B8DE\"> IV - Conjugate gradient </span>\n",
    "**4)** Implement the conjugate-gradient algorithm and test it on a simple quadratic function $p({\\bf x})=\\frac 1 2 {\\bf x^TAx}-{\\bf x^Tb}$ with ${\\bf A} = [1\\; 0;0\\; 5]$ and ${\\bf b}=[1; 1]$.How many steps are required for convergence ? \n",
    "\n",
    "**5)** Consider a larger problem where \n",
    "\n",
    "        n = 10  # 100\n",
    "        \n",
    "        a = randn(n,n)\n",
    "        \n",
    "        A = a'*a + diagm(0=>ones(n)) # A = a'*a\n",
    "        \n",
    "        b = randn(n)\n",
    "\n",
    "For $n=10,100$, check the influence of the condition number of ${\\bf A}$ by adding or removing term **diagm(0=>ones(n))**.\n",
    "\n",
    "## <span style=\"color:#00B8DE\"> V - Polak-Ribière </span>\n",
    "**6)** Considering again function, compare the performance of gradientand Polack-Ribiere algorithms with backtracking and initialization at point $(−4, -2)$. \n",
    "\n",
    "## <span style=\"color:#00B8DE\"> VI - Changing initialization </span>\n",
    "**7)** What occurs with these algorithms when changing intilialization to point $(-5,-0.5)$ ? Explain.\n",
    "\n",
    "\n",
    "## <span style=\"color:#00B8DE\">References (Wikipedia/book)</span>\n",
    "> - [Gradient algorithm](http://en.wikipedia.org/wiki/Gradient_descent)\n",
    "> - [Nonlinear conjugate gradient method and Polack-Ribière algoritm](http://en.wikipedia.org/wiki/Nonlinear_conjugate_gradient_method)\n",
    "> - [Backtracking](http://www.stanford.edu/~boyd/cvxbook/bv_cvxbook.pdf)  (p.464)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------\n",
    "### <span style=\"color:#00B8DE\"> I - Function plot </span>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m Resolving\u001b[22m\u001b[39m package versions...\n",
      "\u001b[32m\u001b[1m Installed\u001b[22m\u001b[39m JSExpr ──────────────── v0.5.1\n",
      "\u001b[32m\u001b[1m Installed\u001b[22m\u001b[39m Plotly ──────────────── v0.2.0\n",
      "\u001b[32m\u001b[1m Installed\u001b[22m\u001b[39m Hiccup ──────────────── v0.2.2\n",
      "\u001b[32m\u001b[1m Installed\u001b[22m\u001b[39m Mustache ────────────── v0.5.13\n",
      "\u001b[32m\u001b[1m Installed\u001b[22m\u001b[39m Pidfile ─────────────── v1.1.0\n",
      "\u001b[32m\u001b[1m Installed\u001b[22m\u001b[39m DocStringExtensions ─── v0.8.1\n",
      "\u001b[32m\u001b[1m Installed\u001b[22m\u001b[39m PlotlyJS ────────────── v0.13.0\n",
      "\u001b[32m\u001b[1m Installed\u001b[22m\u001b[39m WebIO ───────────────── v0.8.11\n",
      "\u001b[32m\u001b[1m Installed\u001b[22m\u001b[39m IniFile ─────────────── v0.5.0\n",
      "\u001b[32m\u001b[1m Installed\u001b[22m\u001b[39m Widgets ─────────────── v0.6.2\n",
      "\u001b[32m\u001b[1m Installed\u001b[22m\u001b[39m FunctionalCollections ─ v0.5.0\n",
      "\u001b[32m\u001b[1m Installed\u001b[22m\u001b[39m Mux ─────────────────── v0.7.0\n",
      "\u001b[32m\u001b[1m Installed\u001b[22m\u001b[39m AssetRegistry ───────── v0.1.0\n",
      "\u001b[32m\u001b[1m Installed\u001b[22m\u001b[39m Lazy ────────────────── v0.13.2\n",
      "\u001b[32m\u001b[1m Installed\u001b[22m\u001b[39m PlotlyBase ──────────── v0.3.0\n",
      "\u001b[32m\u001b[1m Installed\u001b[22m\u001b[39m Observables ─────────── v0.2.3\n",
      "\u001b[32m\u001b[1m Installed\u001b[22m\u001b[39m HTTP ────────────────── v0.8.6\n",
      "\u001b[32m\u001b[1m Installed\u001b[22m\u001b[39m WebSockets ──────────── v1.5.2\n",
      "\u001b[32m\u001b[1m Installed\u001b[22m\u001b[39m Blink ───────────────── v0.12.0\n",
      "\u001b[32m\u001b[1m  Updating\u001b[22m\u001b[39m `~/.julia/environments/v1.2/Project.toml`\n",
      " \u001b[90m [58dd65bb]\u001b[39m\u001b[92m + Plotly v0.2.0\u001b[39m\n",
      "\u001b[32m\u001b[1m  Updating\u001b[22m\u001b[39m `~/.julia/environments/v1.2/Manifest.toml`\n",
      " \u001b[90m [bf4720bc]\u001b[39m\u001b[92m + AssetRegistry v0.1.0\u001b[39m\n",
      " \u001b[90m [ad839575]\u001b[39m\u001b[92m + Blink v0.12.0\u001b[39m\n",
      " \u001b[90m [ffbed154]\u001b[39m\u001b[92m + DocStringExtensions v0.8.1\u001b[39m\n",
      " \u001b[90m [de31a74c]\u001b[39m\u001b[92m + FunctionalCollections v0.5.0\u001b[39m\n",
      " \u001b[90m [cd3eb016]\u001b[39m\u001b[92m + HTTP v0.8.6\u001b[39m\n",
      " \u001b[90m [9fb69e20]\u001b[39m\u001b[92m + Hiccup v0.2.2\u001b[39m\n",
      " \u001b[90m [83e8ac13]\u001b[39m\u001b[92m + IniFile v0.5.0\u001b[39m\n",
      " \u001b[90m [97c1335a]\u001b[39m\u001b[92m + JSExpr v0.5.1\u001b[39m\n",
      " \u001b[90m [50d2b5c4]\u001b[39m\u001b[92m + Lazy v0.13.2\u001b[39m\n",
      " \u001b[90m [ffc61752]\u001b[39m\u001b[92m + Mustache v0.5.13\u001b[39m\n",
      " \u001b[90m [a975b10e]\u001b[39m\u001b[92m + Mux v0.7.0\u001b[39m\n",
      " \u001b[90m [510215fc]\u001b[39m\u001b[92m + Observables v0.2.3\u001b[39m\n",
      " \u001b[90m [fa939f87]\u001b[39m\u001b[92m + Pidfile v1.1.0\u001b[39m\n",
      " \u001b[90m [58dd65bb]\u001b[39m\u001b[92m + Plotly v0.2.0\u001b[39m\n",
      " \u001b[90m [a03496cd]\u001b[39m\u001b[92m + PlotlyBase v0.3.0\u001b[39m\n",
      " \u001b[90m [f0f68f2c]\u001b[39m\u001b[92m + PlotlyJS v0.13.0\u001b[39m\n",
      " \u001b[90m [0f1e0344]\u001b[39m\u001b[92m + WebIO v0.8.11\u001b[39m\n",
      " \u001b[90m [104b5d7c]\u001b[39m\u001b[92m + WebSockets v1.5.2\u001b[39m\n",
      " \u001b[90m [cc8bc4a8]\u001b[39m\u001b[92m + Widgets v0.6.2\u001b[39m\n",
      "\u001b[32m\u001b[1m  Building\u001b[22m\u001b[39m WebIO ───→ `~/.julia/packages/WebIO/2mZPb/deps/build.log`\n",
      "\u001b[32m\u001b[1m  Building\u001b[22m\u001b[39m Blink ───→ `~/.julia/packages/Blink/AO8uN/deps/build.log`\n",
      "\u001b[32m\u001b[1m  Building\u001b[22m\u001b[39m PlotlyJS → `~/.julia/packages/PlotlyJS/b9Efu/deps/build.log`\n"
     ]
    }
   ],
   "source": [
    "import Pkg; \n",
    "Pkg.add(\"Plotly\");\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "∇f (generic function with 1 method)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f(x,y)  = ((x-2)*sin(y-1))^2 + x^2 + y^2 \n",
    "∇f(x,y)  =[2*(x-2)*(sin(y-1))^2+2*x; 2*(x-2)^2 * sin(y-1) * cos(y-1)+2*y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min f(x,y) = 0.7902328773913346\n",
      "optimum at (x*,y*) = (0.09172811859570773,0.7789586896619789)\n"
     ]
    }
   ],
   "source": [
    "opt = [0.09172811859570773;0.7789586896619789]\n",
    "println(\"min f(x,y) = $(f(opt[1],opt[2]))\")\n",
    "println(\"optimum at (x*,y*) = ($(opt[1]),$(opt[2]))\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Plots;\n",
    "pyplot()\n",
    "x = collect(Float16, range(-3,length=100,stop=3));\n",
    "y = collect(Float16, range(-3,length=100, stop=3));\n",
    "z = f.(x,y);# ((x.-2).*sin(y.-1)).^2 + x.^2 + y.^2 ;\n",
    "contour(x,y,z);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Precompiling Plotly [58dd65bb-95f3-509e-9936-c39a10fdeae7]\n",
      "└ @ Base loading.jl:1242\n",
      "WARNING: using HTTP.stack in module Mux conflicts with an existing identifier.\n",
      "WARNING: Method definition savehtml(IO, PlotlyBase.Plot{TT} where TT<:PlotlyBase.AbstractTrace) in module PlotlyBase at /homes/n17zan/.julia/packages/PlotlyBase/80KwD/src/output.jl:40 overwritten in module PlotlyJS at /homes/n17zan/.julia/packages/PlotlyJS/b9Efu/src/display.jl:334.\n",
      "  ** incremental compilation may be fatally broken for this module **\n",
      "\n",
      "WARNING: Method definition savehtml(PlotlyBase.Plot{TT} where TT<:PlotlyBase.AbstractTrace, AbstractString) in module PlotlyBase at /homes/n17zan/.julia/packages/PlotlyBase/80KwD/src/output.jl:52 overwritten in module PlotlyJS at /homes/n17zan/.julia/packages/PlotlyJS/b9Efu/src/display.jl:361.\n",
      "  ** incremental compilation may be fatally broken for this module **\n",
      "\n",
      "WARNING: Method definition savehtml(IO, PlotlyBase.Plot{TT} where TT<:PlotlyBase.AbstractTrace) in module PlotlyBase at /homes/n17zan/.julia/packages/PlotlyBase/80KwD/src/output.jl:40 overwritten in module PlotlyJS at /homes/n17zan/.julia/packages/PlotlyJS/b9Efu/src/display.jl:334.\n",
      "  ** incremental compilation may be fatally broken for this module **\n",
      "\n",
      "WARNING: Method definition savehtml(PlotlyBase.Plot{TT} where TT<:PlotlyBase.AbstractTrace, AbstractString) in module PlotlyBase at /homes/n17zan/.julia/packages/PlotlyBase/80KwD/src/output.jl:52 overwritten in module PlotlyJS at /homes/n17zan/.julia/packages/PlotlyJS/b9Efu/src/display.jl:361.\n",
      "  ** incremental compilation may be fatally broken for this module **\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<script>\n",
       "// Immediately-invoked-function-expression to avoid global variables.\n",
       "(function() {\n",
       "    var warning_div = document.getElementById(\"webio-warning-6987488216158912258\");\n",
       "    var hide = function () {\n",
       "        var script = document.getElementById(\"webio-setup-8427946949610078913\");\n",
       "        var parent = script && script.parentElement;\n",
       "        var grandparent = parent && parent.parentElement;\n",
       "        if (grandparent) {\n",
       "            grandparent.style.display = \"none\";\n",
       "        }\n",
       "        warning_div.style.display = \"none\";\n",
       "    };\n",
       "    if (typeof Jupyter !== \"undefined\") {\n",
       "        console.log(\"WebIO detected Jupyter notebook environment.\");\n",
       "        // Jupyter notebook.\n",
       "        var extensions = (\n",
       "            Jupyter\n",
       "            && Jupyter.notebook.config.data\n",
       "            && Jupyter.notebook.config.data.load_extensions\n",
       "        );\n",
       "        if (extensions && extensions[\"webio-jupyter-notebook\"]) {\n",
       "            // Extension already loaded.\n",
       "            console.log(\"Jupyter WebIO nbextension detected; not loading ad-hoc.\");\n",
       "            hide();\n",
       "            return;\n",
       "        }\n",
       "    } else if (window.location.pathname.includes(\"/lab\")) {\n",
       "        // Guessing JupyterLa\n",
       "        console.log(\"Jupyter Lab detected; make sure the @webio/jupyter-lab-provider labextension is installed.\");\n",
       "        hide();\n",
       "        return;\n",
       "    }\n",
       "})();\n",
       "\n",
       "</script>\n",
       "<p\n",
       "    id=\"webio-warning-6987488216158912258\"\n",
       "    class=\"output_text output_stderr\"\n",
       "    style=\"padding: 1em; font-weight: bold;\"\n",
       ">\n",
       "    Unable to load WebIO. Please make sure WebIO works for your Jupyter client.\n",
       "    For troubleshooting, please see <a href=\"https://juliagizmos.github.io/WebIO.jl/latest/providers/ijulia/\">\n",
       "    the WebIO/IJulia documentation</a>.\n",
       "    <!-- TODO: link to installation docs. -->\n",
       "</p>\n"
      ],
      "text/plain": [
       "HTML{String}(\"<script>\\n// Immediately-invoked-function-expression to avoid global variables.\\n(function() {\\n    var warning_div = document.getElementById(\\\"webio-warning-6987488216158912258\\\");\\n    var hide = function () {\\n        var script = document.getElementById(\\\"webio-setup-8427946949610078913\\\");\\n        var parent = script && script.parentElement;\\n        var grandparent = parent && parent.parentElement;\\n        if (grandparent) {\\n            grandparent.style.display = \\\"none\\\";\\n        }\\n        warning_div.style.display = \\\"none\\\";\\n    };\\n    if (typeof Jupyter !== \\\"undefined\\\") {\\n        console.log(\\\"WebIO detected Jupyter notebook environment.\\\");\\n        // Jupyter notebook.\\n        var extensions = (\\n            Jupyter\\n            && Jupyter.notebook.config.data\\n            && Jupyter.notebook.config.data.load_extensions\\n        );\\n        if (extensions && extensions[\\\"webio-jupyter-notebook\\\"]) {\\n            // Extension already loaded.\\n            console.log(\\\"Jupyter WebIO nbextension detected; not loading ad-hoc.\\\");\\n            hide();\\n            return;\\n        }\\n    } else if (window.location.pathname.includes(\\\"/lab\\\")) {\\n        // Guessing JupyterLa\\n        console.log(\\\"Jupyter Lab detected; make sure the @webio/jupyter-lab-provider labextension is installed.\\\");\\n        hide();\\n        return;\\n    }\\n})();\\n\\n</script>\\n<p\\n    id=\\\"webio-warning-6987488216158912258\\\"\\n    class=\\\"output_text output_stderr\\\"\\n    style=\\\"padding: 1em; font-weight: bold;\\\"\\n>\\n    Unable to load WebIO. Please make sure WebIO works for your Jupyter client.\\n    For troubleshooting, please see <a href=\\\"https://juliagizmos.github.io/WebIO.jl/latest/providers/ijulia/\\\">\\n    the WebIO/IJulia documentation</a>.\\n    <!-- TODO: link to installation docs. -->\\n</p>\\n\")"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "LoadError",
     "evalue": "syntax: unexpected comma in matrix expression",
     "output_type": "error",
     "traceback": [
      "syntax: unexpected comma in matrix expression",
      ""
     ]
    }
   ],
   "source": [
    "# For options of Plots.jl, see https://docs.juliaplots.org/latest/\n",
    "using Plotly;\n",
    "pyplot()\n",
    "n = 100;\n",
    "x = range(-3, stop=3, length=n);\n",
    "y = range(-3, stop=3, length=n);\n",
    "z = f.(x,y);\n",
    "#contour(x,y,z);\n",
    "data = [\n",
    "  [\n",
    "    \"z\" =&gt; z,\n",
    "    \"x\" =&gt; x,\n",
    "    \"y\" =&gt; y,\n",
    "    \"type\" =&gt; \"contour\"\n",
    "  ]\n",
    "]\n",
    "response = Plotly.plot(data, [\"filename\" =&gt; \"simple-contour\", \"fileopt\" =&gt; \"overwrite\"])\n",
    "plot_url = response[\"url\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "syntax: incomplete: \"for\" at none:2 requires end",
     "output_type": "error",
     "traceback": [
      "syntax: incomplete: \"for\" at none:2 requires end",
      ""
     ]
    }
   ],
   "source": [
    "using Plotly\n",
    "\n",
    "size = 100\n",
    "x = range(-2*pi, stop=2*pi, size)\n",
    "y = range(-2*pi, stop=2*pi, size)\n",
    "z = rand(size, size)\n",
    "for i = 1:size\n",
    "  for j = 1:size\n",
    "    r2 = (x(i)^2 + y(j)^2)\n",
    "        z(i,j) = sin(x(i))*cos(y(j))*sin(r2)/log(r2+1)\n",
    "\n",
    "\n",
    "data = [\n",
    "  [\n",
    "    \"z\" =&gt; z\n",
    "    \"x\" =&gt; x\n",
    "    \"y\" =&gt; y\n",
    "    \"type\" =&gt; \"contour\"\n",
    "  ]\n",
    "]\n",
    "response = Plotly.plot(data, [\"filename\" =&gt; \"simple-contour\"; \"fileopt\" =&gt; \"overwrite\"])\n",
    "plot_url = response[\"url\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:#00B8DE\"> II - Backtracking </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gradient algorithm\n",
    "# constant stepsize\n",
    "#-------------------\n",
    "using LinearAlgebra: norm, transpose\n",
    "precision = 1.e-8\n",
    "max_iter  = 10e4\n",
    "init      = [-4, -2]#[-5,-.5]\n",
    "\n",
    "# Constant stepsize\n",
    "pt         = init\n",
    "nb_const   = 0 # number of loops\n",
    "resu_const = pt\n",
    "while norm(pt-opt)>precision && nb_const<max_iter\n",
    "    pt = pt- 0.01 * ∇f(pt[1],pt[2])\n",
    "    resu_const  = [resu_const pt]\n",
    "    nb_const+=1\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "backtracking (generic function with 1 method)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Backtracking\n",
    "#-------------\n",
    "function backtracking(x,f,∇f,d)\n",
    "    \"\"\"\n",
    "    bactracking: \n",
    "    see e.g. https://web.stanford.edu/~boyd/cvxbook/bv_cvxbook.pdf - p.464\n",
    "    IN:\n",
    "    ---\n",
    "    x: initial point\n",
    "    f, ∇f: function to be minimized and its gradient\n",
    "    d: searc direction\n",
    "    OUT:\n",
    "    ----\n",
    "    y: final point\n",
    "    n: number of loops\n",
    "    \"\"\"\n",
    "    t = 1\n",
    "    alpha = 0.25\n",
    "    beta = 0.7\n",
    "    numberLoop = 0\n",
    "    gradient = ∇f(x[1],x[2])\n",
    "    while(f(x[1]+t*d[1],x[2]+t*d[2]) >f(x[1],x[2])+(alpha*t)*(transpose(gradient)*d))\n",
    "        t=beta*t\n",
    "        numberLoop+=1\n",
    "    end\n",
    "    x = x- t* ∇f(x[1],x[2]) \n",
    "    #d=.-∇f(pt[1],pt[2])   \n",
    "    return (x, numberLoop)\n",
    "    \n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gradient algorithm\n",
    "# with backtracking\n",
    "#-------------------\n",
    "pt             = init\n",
    "nb_iter_grad   = 0  # number of loops\n",
    "nb_loops_grad  = 0  # number of inner loops count for backtracking\n",
    "resu_grad      = pt\n",
    "while norm(pt-opt)>precision && nb_iter_grad<max_iter\n",
    "    (pt,numberLoop)=backtracking(pt,f,∇f, -∇f(pt[1],pt[2]))\n",
    "    nb_loops_grad+=numberLoop\n",
    "    nb_iter_grad+=1\n",
    "    resu_grad      = [resu_grad pt]\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error with constant stepsize: 9.980669070114126e-9\n",
      "Number of iterations with constant stepsize: 1491\n",
      "\n",
      "\n",
      "Error with backtracking: 7.651366552586751e-9\n",
      "Number of iterations for backtracking= 45\n",
      "Number of inner loops for backtracking = 223\n"
     ]
    }
   ],
   "source": [
    "println(\"Error with constant stepsize: $(norm(resu_const[:,end]-opt))\")\n",
    "println(\"Number of iterations with constant stepsize: $nb_const\\n\\n\")\n",
    "    \n",
    "println(\"Error with backtracking: $(norm(resu_grad[:,end]-opt))\")\n",
    "println(\"Number of iterations for backtracking= $nb_iter_grad\")\n",
    "println(\"Number of inner loops for backtracking = $nb_loops_grad\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:#00B8DE\"> III - Gradient and Newton </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "backtracking (generic function with 2 methods)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function backtracking(x,f,∇f,∇2f, d)\n",
    "    \"\"\"\n",
    "    bactracking: \n",
    "    see e.g. https://web.stanford.edu/~boyd/cvxbook/bv_cvxbook.pdf - p.464\n",
    "    IN:\n",
    "    ---\n",
    "    x: initial point\n",
    "    f, ∇f: function to be minimized and its gradient\n",
    "    d: searc direction\n",
    "    OUT:\n",
    "    ----\n",
    "    y: final point\n",
    "    n: number of loops\n",
    "    \"\"\"\n",
    "    t = 1\n",
    "    alpha = 0.25\n",
    "    beta = 0.7\n",
    "    numberLoop = 0\n",
    "    gradient = ∇f(x[1],x[2])\n",
    "    while(f(x[1]+t*d[1],x[2]+t*d[2]) >f(x[1],x[2])+(alpha*t)*(transpose(gradient)*d))\n",
    "        t=beta*t\n",
    "        numberLoop+=1\n",
    "    end\n",
    "    x = x - inv(∇2f(x[1],x[2])) * ∇f(x[1],x[2])\n",
    "    #d=.-∇f(pt[1],pt[2])   \n",
    "    return (x, numberLoop)\n",
    "    \n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Newton algorithm (with backtracking)\n",
    "#-------------------------------------\n",
    "∇2f(x,y) = [[2*(sin(y-1)^2)+2 2*(x-2)*sin(2y-2)];[2*(x-2)*sin(2y-2) 2*(x-2)^2*cos(2*y-2)+2]]\n",
    "\n",
    "pt        = init\n",
    "nb_iter   = 0        # number of loops\n",
    "nb_loops  = 0        # number of inner loops count for backtracking\n",
    "resu_N    = pt\n",
    "while norm(pt-opt)>precision && nb_iter<max_iter\n",
    "    (pt,numberLoop) = backtracking(pt,f,∇f,∇2f,-∇f(pt[1],pt[2]))\n",
    "    nb_loops+=numberLoop\n",
    "    nb_iter+=1\n",
    "    resu_N = [resu_N pt]\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error with Newton+backtracking: 6.996747706783417e-10\n",
      "Number of iterations for Newton= 60\n",
      "Number of inner loops for Newton = 160\n"
     ]
    }
   ],
   "source": [
    "println(\"Error with Newton+backtracking: $(norm(resu_N[:,end]-opt))\")\n",
    "println(\"Number of iterations for Newton= $nb_iter\")\n",
    "println(\"Number of inner loops for Newton = $nb_loops\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.7083207988800078, 8.97065095290153]\n"
     ]
    }
   ],
   "source": [
    "using LinearAlgebra: eigvals\n",
    "println(eigvals(∇2f(pt[1],pt[2])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "syntax: invalid identifier name \"...\"",
     "output_type": "error",
     "traceback": [
      "syntax: invalid identifier name \"...\"",
      ""
     ]
    }
   ],
   "source": [
    "# Figure: gradient and Newton with backtracking\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:#00B8DE\"> IV - Conjugate gradient </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2-element Array{Float64,1}:\n",
       " 1.0\n",
       " 0.2"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using LinearAlgebra: norm\n",
    "\n",
    "A=[1 0;0 5]\n",
    "b=[1,1]\n",
    "p(x,y)  = 0.5*transpose([x;y])*A*[x;y] - transpose([x;y])*b\n",
    "∇p(x,y) = A * [x;y] - b\n",
    "opt= inv(A)*b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision = 1.e-8\n",
    "max_iter  = 10e4\n",
    "init      = [-2,3]\n",
    "\n",
    "# optimal stepsize\n",
    "pt            = init\n",
    "nb_opt_grad   = 0 # number of loops\n",
    "resu_opt_grad = pt\n",
    "alpha = 0.01\n",
    "#r = - ∇p(pt[1],pt[2])\n",
    "#pd = r\n",
    "while norm(pt-opt)>precision && nb_opt_grad<max_iter\n",
    "    pt = pt - alpha * ∇p(pt[1], pt[2])\n",
    "    resu_opt_grad = [resu_opt_grad pt]\n",
    "    nb_opt_grad+=1\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error with gradient with optimal stepsize: 9.915265608562155e-9\n",
      "Number of iterations = 1943\n"
     ]
    }
   ],
   "source": [
    "println(\"Error with gradient with optimal stepsize: $(norm(resu_opt_grad[:,end]-opt))\")\n",
    "println(\"Number of iterations = $nb_opt_grad\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "syntax: invalid identifier name \"...\"",
     "output_type": "error",
     "traceback": [
      "syntax: invalid identifier name \"...\"",
      ""
     ]
    }
   ],
   "source": [
    "# For options of Plots.jl, see https://docs.juliaplots.org/latest/\n",
    "using Plots\n",
    "pyplot()\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-2, 3][-2.0 -1.378159757330637; 3.0 0.09807886754297268][-2.0 -1.378159757330637 1.0; 3.0 0.09807886754297268 0.19999999999999923]"
     ]
    }
   ],
   "source": [
    "# Conjugate gradient\n",
    "#--------------------\n",
    "pt          = init\n",
    "nb_iter_CG  = 0        # number of iterations\n",
    "nb_loops_CG = 0        # number of inner loops count for backtracking\n",
    "err_CG      = norm(pt-opt)\n",
    "# initialization\n",
    "r = - ∇p(pt[1],pt[2])\n",
    "pd = r          \n",
    "resu_CG = pt\n",
    "# iterations\n",
    "for k = 1:2\n",
    "    alpha = (transpose(r) * r)/(transpose(pd)*A*pd)\n",
    "    pt = pt + alpha * pd\n",
    "    rOld = r\n",
    "    r = r - alpha*A*pd\n",
    "    beta = (transpose(r)*r)/(transpose(rOld)*rOld)\n",
    "    pd= r + beta*pd\n",
    "    nb_opt_grad+=1\n",
    "    print(resu_CG)\n",
    "    resu_CG = [resu_CG pt]\n",
    "    err_CG = [err_CG norm(pt-opt)]\n",
    "end\n",
    "print(resu_CG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error with CG: 7.771561172376096e-16\n",
      "Error number of iterations with CG: 3\n"
     ]
    }
   ],
   "source": [
    "println(\"Error with CG: $(err_CG[end])\")\n",
    "println(\"Error number of iterations with CG: $(size(resu_CG)[2])\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure: gradient with optimal step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A larger problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "382.0133736243563\n"
     ]
    },
    {
     "data": {
      "image/png": "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"
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using Plots:plot\n",
    "using LinearAlgebra: cond, diagm, norm\n",
    "\n",
    "n = 100\n",
    "A = randn(n,n)\n",
    "A = A'*A + diagm(0=>ones(n))\n",
    "println(cond(A))\n",
    "b = randn(n)\n",
    "opt = inv(A) * b\n",
    "\n",
    "pt          = randn(n)\n",
    "err_CG      = norm(pt-opt)\n",
    "\n",
    "# initialization\n",
    "p(x)  = 0.5*transpose(x)*A*x - transpose(x)*b\n",
    "∇p(x) = A * x - b\n",
    "r = - ∇p(pt)\n",
    "pd = r                    \n",
    "# iterations\n",
    "for k = 1:n\n",
    "    alpha = (transpose(r) * r)/(transpose(pd)*A*pd)\n",
    "    pt = pt + alpha * pd\n",
    "    rOld = r\n",
    "    r = r - alpha*A*pd\n",
    "    beta = (transpose(r)*r)/(transpose(rOld)*rOld)\n",
    "    pd= r + beta*pd\n",
    "    err_CG = [err_CG;norm(pt.-opt)]\n",
    "end\n",
    "plot(err_CG/norm(opt),yscale=:log10,label=\"error norm of CG\",size=(400,300))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:#00B8DE\"> V - Polak-Ribière </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <span style=\"color:#00B8DE\">Polack-Ribière method</span>\n",
    "\n",
    "Initialization: \n",
    "\n",
    "> 1. initialize ${\\bf x_0}$ and calculate $\\Delta {\\bf x_0}$, where $\\Delta {\\bf x_n}= - \\nabla f ({\\bf x_n})$ \n",
    "> 2. $\\alpha_0 = \\arg \\min_\\alpha f({\\bf x_0}+\\alpha \\Delta {\\bf x_0})$\n",
    "> 3. ${\\bf x_1}={\\bf x_0}+\\alpha_0 \\Delta {\\bf x_0}$\n",
    "\n",
    "Iterations: \n",
    "\n",
    "> 1. $\\beta_{n} = \\frac{\\nabla f ({\\bf x_n})^{\\top} (\\nabla f ( {\\bf x_n})-\\nabla f ({\\bf x_{n-1}}))} {\\nabla f ({\\bf x_{n-1})^{\\top}} \\nabla f ({\\bf x_{n-1}})}$\n",
    "> 2. ${\\bf d_n}= -\\nabla f ({\\bf x_n})+\\beta_n {\\bf d_{n-1}}$\n",
    "> 3. $\\alpha_n=\\arg \\min_{\\alpha} f({\\bf x_n}+\\alpha {\\bf d_n})$\n",
    "> 4. ${\\bf x_{n+1}}={\\bf x_n}+\\alpha_{n} {\\bf d_n}$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "backtracking (generic function with 2 methods)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function backtracking(x,f,∇f,d)\n",
    "    \"\"\"\n",
    "    bactracking: \n",
    "    see e.g. https://web.stanford.edu/~boyd/cvxbook/bv_cvxbook.pdf - p.464\n",
    "    IN:\n",
    "    ---\n",
    "    x: initial point\n",
    "    f, ∇f: function to be minimized and its gradient\n",
    "    d: searc direction\n",
    "    OUT:\n",
    "    ----\n",
    "    t: stepsize\n",
    "    n: number of loops\n",
    "    \"\"\"\n",
    "    t = 1\n",
    "    alpha = 0.25\n",
    "    beta = 0.7\n",
    "    numberLoop = 0\n",
    "    gradient = ∇f(x[1],x[2])\n",
    "    while(f(x[1]+t*d[1],x[2]+t*d[2]) >f(x[1],x[2])+(alpha*t)*(transpose(gradient)*d))\n",
    "        t=beta*t\n",
    "        numberLoop+=1\n",
    "    end  \n",
    "    return (t, numberLoop)\n",
    "    \n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Polak-Ribière\n",
    "#---------------\n",
    "using LinearAlgebra: norm, transpose\n",
    "precision = 1.e-8\n",
    "max_iter  = 10e4\n",
    "init      = [-4, -2]#[-5,-.5]\n",
    "pt          = init\n",
    "nb_iter_PR  = 0        # number of iterations\n",
    "nb_loops_PR = 0        # number of inner loops count for backtracking\n",
    "resu_PR     = pt\n",
    "opt = [0.09172811859570773;0.7789586896619789]\n",
    "\n",
    "f(x,y)  = ((x-2)*sin(y-1))^2 + x^2 + y^2 \n",
    "∇f(x,y)  =[2*(x-2)*(sin(y-1))^2+2*x; 2*(x-2)^2 * sin(y-1) * cos(y-1)+2*y]\n",
    "\n",
    "# initialization\n",
    "r = -∇f(pt[1],pt[2])\n",
    "pd = r \n",
    "(alpha, numberLoop)= backtracking(pt,f,∇f,pd)\n",
    "nb_loops_PR+=numberLoop\n",
    "ptOld = pt\n",
    "pt = pt + alpha * pd\n",
    "\n",
    "# iterations\n",
    "while norm(pt-opt)>precision && nb_iter_PR<max_iter\n",
    "    # iterations\n",
    "    gradPt = ∇f(pt[1],pt[2])\n",
    "    gradOldPt = ∇f(ptOld[1],ptOld[2])\n",
    "    beta = transpose(gradPt)*(gradPt-gradOldPt)/(transpose(gradOldPt)*gradOldPt)\n",
    "    pd = -gradPt + beta*pd\n",
    "    (alpha, numberLoop)= backtracking(pt,f,∇f,pd)\n",
    "    nb_loops_PR+=numberLoop\n",
    "    ptOld = pt\n",
    "    pt = pt + alpha * pd\n",
    "    resu_PR = [resu_PR pt]\n",
    "    nb_iter_PR+=1\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error with gradient = 7.651366552586751e-9\n",
      "Number of iterations = 45\n",
      "Number of inner loops = 223\n",
      "\n",
      "Error with Polack-Ribière = 4.364291720413405e-9\n",
      "Number of iterations = 45\n",
      "Number of inner loops = 522\n"
     ]
    }
   ],
   "source": [
    "println(\"Error with gradient = $(norm(resu_grad[:,end]-opt))\")\n",
    "println(\"Number of iterations = $nb_iter_grad\")\n",
    "println(\"Number of inner loops = $nb_loops_grad\\n\")\n",
    "\n",
    "println(\"Error with Polack-Ribière = $(norm(resu_PR[:,end]-opt))\")\n",
    "println(\"Number of iterations = $nb_iter_PR\")\n",
    "println(\"Number of inner loops = $nb_loops_PR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Figure: Gradient and Polack-Ribière (with backtraking)\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Julia 1.2.0",
   "language": "julia",
   "name": "julia-1.2"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
